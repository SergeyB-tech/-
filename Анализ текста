# Вот программа на Python, которая анализирует текстовые файлы и выводит статистику в удобочитаемом формате:

1. **Импорты**:
   - `re` - модуль для работы с регулярными выражениями (для разделения текста на слова и предложения)
   - `Counter` из `collections` - удобный инструмент для подсчета частоты элементов

2. **Функция `analyze_text(file_path)`**:
   - Читает файл по указанному пути
   - Обрабатывает возможные ошибки чтения файла
   - Подсчитывает:
     - Символы (включая все символы, включая пробелы и знаки препинания)
     - Предложения (разделяет текст по знакам .!?)
     - Слова (использует регулярное выражение для поиска последовательностей букв)
     - Частоту слов с помощью Counter

3. **Функция `print_statistics(stats)`**:
   - Форматирует и красиво выводит полученную статистику
   - Показывает общие цифры и топ-10 самых частых слов

4. **Основной блок (`__name__ == "__main__"`)**:
   - Запрашивает у пользователя путь к файлу
   - Запускает анализ и вывод результатов

### Особенности работы программы:
1. Подсчет предложений - это приблизительная оценка, так как в реальном тексте могут быть сложные случаи (например, сокращения с точками).
2. Слова приводятся к нижнему регистру, чтобы "Привет" и "привет" считались одним словом.
3. Программа обрабатывает русские и английские слова.
4. Выводится топ-10 самых частых слов, но это число можно изменить в коде.

### Пример использования:
1. Сохраните код в файл `text_analyzer.py`
2. Запустите: `python text_analyzer.py`
3. Введите путь к текстовому файлу при запросе
4. Получите статистику по файлу

Программа может быть легко расширена для добавления дополнительной статистики, такой как средняя длина слова, средняя длина предложения и т.д.
