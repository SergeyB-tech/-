# Анализ текста


# 1. Импорты:

re - модуль для работы с регулярными выражениями (для разделения текста на слова и предложения)

Counter из collections - удобный инструмент для подсчета частоты элементов

# 2. Функция analyze_text(file_path):

Читает файл по указанному пути

Обрабатывает возможные ошибки чтения файла

Подсчитывает:

```Символы (включая все символы, включая пробелы и знаки препинания)```

```Предложения (разделяет текст по знакам .!?)```

```Слова (использует регулярное выражение для поиска последовательностей букв)```

```Частоту слов с помощью Counter```

# 3. Функция print_statistics(stats):

Форматирует и красиво выводит полученную статистику

Показывает общие цифры и топ-10 самых частых слов

# 4. Основной блок (__name__ == "__main__"):

Запрашивает у пользователя путь к файлу

Запускает анализ и вывод результатов

# Особенности работы программы:

Подсчет предложений - это приблизительная оценка, так как в реальном тексте могут быть сложные случаи (например, сокращения с точками).

Слова приводятся к нижнему регистру, чтобы "Привет" и "привет" считались одним словом.

Программа обрабатывает русские и английские слова.

Выводится топ-10 самых частых слов, но это число можно изменить в коде.

# Пример использования:

Сохраните код в файл text_analyzer.py

Запустите: python text_analyzer.py

Введите путь к текстовому файлу при запросе

Получите статистику по файлу

Программа может быть легко расширена для добавления дополнительной статистики, такой как средняя длина слова, средняя длина предложения и т.д.
